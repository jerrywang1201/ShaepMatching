{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"garythung/trashnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the Dataset\n",
    "\n",
    "This section prints the overall dataset structure and previews the first five samples from the training subset.  \n",
    "It helps verify that the dataset has been loaded correctly and provides an overview of the data fields, including images and their corresponding labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 5054\n",
      "    })\n",
      "})\n",
      "{'image': [<PIL.Image.Image image mode=RGB size=3024x4032 at 0x1F2A94F3BD0>, <PIL.Image.Image image mode=RGB size=3024x4032 at 0x1F290BC4E10>, <PIL.Image.Image image mode=RGB size=4032x3024 at 0x1F28FF31FD0>, <PIL.Image.Image image mode=RGB size=3024x4032 at 0x1F2A98E00D0>, <PIL.Image.Image image mode=RGB size=3024x4032 at 0x1F2A97BB7D0>], 'label': [0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(ds)\n",
    "train_ds = ds['train']  # or ds['test']\n",
    "print(train_ds[:5])  # first 5 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Image Classification on TrashNet Dataset\n",
    "\n",
    "This section trains a convolutional neural network (CNN) on the TrashNet dataset using PyTorch.  \n",
    "The process includes loading and preprocessing images, splitting the dataset into training and testing sets, defining a CNN architecture, and training the model for three epochs.  \n",
    "After training, the model is evaluated on the test set to compute overall classification accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 done. Avg loss: 1.3705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 done. Avg loss: 1.0448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 done. Avg loss: 0.8892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 32/32 [02:49<00:00,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final Test Accuracy: 62.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Load dataset ---\n",
    "# Assigns a preloaded dataset object (ds) to the variable 'dataset'\n",
    "dataset = ds\n",
    "\n",
    "# --- Preprocessing ---\n",
    "# Defines a sequence of image transformations:\n",
    "# 1. Resizes all images to 64x64 pixels\n",
    "# 2. Converts PIL images to PyTorch tensors\n",
    "# 3. Normalizes pixel values to the range [-1, 1] using mean and standard deviation of 0.5\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Custom PyTorch Dataset class for handling the Hugging Face dataset\n",
    "class TrashNetTorch(Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None):\n",
    "        # Stores dataset and optional transformation\n",
    "        self.data = hf_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns total number of samples in the dataset\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieves one sample (image and label) from the dataset\n",
    "        image = self.data[idx][\"image\"].convert(\"RGB\")  # Ensures image is in RGB format\n",
    "        label = self.data[idx][\"label\"]\n",
    "        # Applies transformation if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# --- Manual split (80% train, 20% test) ---\n",
    "# Converts Hugging Face dataset to a PyTorch Dataset and applies preprocessing\n",
    "full_data = TrashNetTorch(dataset[\"train\"], transform)\n",
    "\n",
    "# Calculates number of samples for training and testing\n",
    "train_size = int(0.8 * len(full_data))\n",
    "test_size = len(full_data) - train_size\n",
    "\n",
    "# Randomly splits the dataset into training and testing subsets\n",
    "train_data, test_data = random_split(full_data, [train_size, test_size])\n",
    "\n",
    "# Creates DataLoader objects to handle batching and shuffling of data\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# --- CNN Model ---\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Defines two convolutional layers with ReLU activations and max pooling\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),  # Input: 3 channels, Output: 16 channels\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),              # Reduces spatial dimensions by factor of 2\n",
    "            nn.Conv2d(16, 32, 3, padding=1), # Input: 16 channels, Output: 32 channels\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)               # Further reduces spatial dimensions\n",
    "        )\n",
    "        # Defines two fully connected layers for classification\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),                    # Flattens feature maps into a single vector\n",
    "            nn.Linear(32 * 16 * 16, 128),    # Fully connected layer with 128 units\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 6)                # Output layer with 6 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Defines forward pass through convolutional and fully connected layers\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "# Determines whether to use GPU (CUDA) or CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Instantiates model and moves it to selected device\n",
    "model = CNN().to(device)\n",
    "\n",
    "# Defines loss function and optimization algorithm\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# --- Training ---\n",
    "for epoch in range(3):\n",
    "    model.train()  # Sets model to training mode\n",
    "    total_loss = 0\n",
    "    # Initializes progress bar for the training loop\n",
    "    progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/3\", leave=False)\n",
    "    for images, labels in progress:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()               # Resets gradients before each batch\n",
    "        outputs = model(images)             # Forward pass\n",
    "        loss = criterion(outputs, labels)   # Computes loss\n",
    "        loss.backward()                     # Backpropagation\n",
    "        optimizer.step()                    # Updates model parameters\n",
    "        total_loss += loss.item()           # Accumulates loss for monitoring\n",
    "        progress.set_postfix(loss=loss.item())  # Displays current batch loss\n",
    "    # Prints average loss for the completed epoch\n",
    "    print(f\"Epoch {epoch+1} done. Avg loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# --- Evaluation ---\n",
    "model.eval()  # Sets model to evaluation mode\n",
    "correct, total = 0, 0\n",
    "# Disables gradient calculation for evaluation\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)             # Forward pass\n",
    "        _, predicted = torch.max(outputs, 1) # Selects class with highest probability\n",
    "        total += labels.size(0)              # Counts total samples\n",
    "        correct += (predicted == labels).sum().item()  # Counts correct predictions\n",
    "\n",
    "# Calculates and prints final test accuracy\n",
    "acc = 100 * correct / total\n",
    "print(f\"✅ Final Test Accuracy: {acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trashnet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
