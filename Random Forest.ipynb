{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"garythung/trashnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the Dataset\n",
    "\n",
    "This section prints the overall dataset structure and previews the first five samples from the training subset.  \n",
    "It helps verify that the dataset has been loaded correctly and provides an overview of the data fields, including images and their corresponding labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 5054\n",
      "    })\n",
      "})\n",
      "{'image': [<PIL.Image.Image image mode=RGB size=3024x4032 at 0x18892879ED0>, <PIL.Image.Image image mode=RGB size=3024x4032 at 0x1889348A6D0>, <PIL.Image.Image image mode=RGB size=4032x3024 at 0x188949F3C50>, <PIL.Image.Image image mode=RGB size=3024x4032 at 0x18894C13BD0>, <PIL.Image.Image image mode=RGB size=3024x4032 at 0x1889343FA10>], 'label': [0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(ds)\n",
    "train_ds = ds['train']  # or ds['test']\n",
    "print(train_ds[:5])  # first 5 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Images to Numpy Arrays\n",
    "\n",
    "This section preprocesses the images from the training dataset and converts them into numerical arrays suitable for machine learning models.\n",
    "\n",
    "Each image is:\n",
    "1. Resized to a fixed dimension of 128×128 pixels to ensure uniform input size.\n",
    "2. Flattened into a one-dimensional vector for easy storage and compatibility with certain models.\n",
    "3. Stored along with its label in separate NumPy arrays.\n",
    "\n",
    "A progress bar (`tqdm`) is used to visualize the preprocessing progress.  \n",
    "After processing, the resulting feature matrix `X` and label array `y` are displayed with their corresponding shapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 5054/5054 [09:24<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (5054, 49152)\n",
      "Labels shape: (5054,)\n"
     ]
    }
   ],
   "source": [
    "# Define target image size for resizing\n",
    "# Smaller dimensions reduce computational cost and memory usage\n",
    "IMAGE_SIZE = (128, 128)\n",
    "\n",
    "# Initialize empty lists to store flattened image data and labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# Iterate through each sample in the training dataset with a progress bar\n",
    "for example in tqdm(train_ds, desc=\"Processing images\"):\n",
    "    # Resize image to the defined dimensions\n",
    "    img = example['image'].resize(IMAGE_SIZE)\n",
    "    # Convert image to a NumPy array and flatten it into a 1D vector\n",
    "    img_array = np.array(img).flatten()\n",
    "    # Append flattened image to the feature list\n",
    "    X.append(img_array)\n",
    "    # Append the corresponding label\n",
    "    y.append(example['label'])\n",
    "\n",
    "# Convert lists to NumPy arrays for numerical computation\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Display the shape of the feature matrix (samples × features)\n",
    "# and the label vector (samples)\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data into Training and Testing Sets\n",
    "\n",
    "This step divides the dataset into training and testing subsets using an 80/20 ratio.  \n",
    "The training set is used to train the model, while the testing set is used to evaluate its performance on unseen data.  \n",
    "A fixed `random_state` ensures the split is reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the feature matrix (X) and labels (y) into training and testing sets\n",
    "# test_size=0.2 → 20% of the data is reserved for testing\n",
    "# random_state=42 → ensures reproducibility of the split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Evaluating a Random Forest Classifier\n",
    "\n",
    "This section applies a Random Forest classifier to the processed dataset.\n",
    "\n",
    "1. **Model creation:** Initializes a Random Forest with 100 decision trees for ensemble learning.  \n",
    "2. **Training:** Fits the model on the training data (`X_train`, `y_train`).  \n",
    "3. **Prediction:** Uses the trained model to predict labels for the test set.  \n",
    "4. **Evaluation:** Assesses performance using accuracy, a classification report (precision, recall, F1-score), and a confusion matrix to visualize misclassifications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6913946587537092\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.73      0.77       176\n",
      "           1       0.61      0.66      0.63       216\n",
      "           2       0.59      0.51      0.55       164\n",
      "           3       0.72      0.85      0.78       220\n",
      "           4       0.70      0.75      0.72       179\n",
      "           5       0.92      0.39      0.55        56\n",
      "\n",
      "    accuracy                           0.69      1011\n",
      "   macro avg       0.72      0.65      0.67      1011\n",
      "weighted avg       0.70      0.69      0.69      1011\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[129   4  15  21   7   0]\n",
      " [  3 142  25  16  29   1]\n",
      " [  7  43  84  17  12   1]\n",
      " [  8   6   9 187  10   0]\n",
      " [  6  20   5  13 135   0]\n",
      " [  6  17   4   6   1  22]]\n"
     ]
    }
   ],
   "source": [
    "# Create Random Forest classifier\n",
    "# n_estimators=100 → number of decision trees in the ensemble\n",
    "# random_state=42 → ensures consistent results across runs\n",
    "# n_jobs=-1 → utilizes all available CPU cores for faster computation\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the model on the training data\n",
    "# The classifier learns patterns between input features (X_train) and labels (y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on the test data\n",
    "# The model outputs predicted class labels for X_test\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate performance metrics\n",
    "# Accuracy → proportion of correct predictions\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Classification report → includes precision, recall, and F1-score for each class\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix → displays counts of true vs. predicted labels\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
